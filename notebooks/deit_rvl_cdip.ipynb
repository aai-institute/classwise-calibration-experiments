{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# DeiT calibration experiment on RVL-CDIP Dataset\n",
    "\n",
    "We compare multiple calibration algorithms with their reduced, \n",
    "class-wise and class-wise reduced counterparts.\n",
    "\n",
    "We work with a DeiT classifier pre-trained on IIT-CDIP\n",
    "and then finetuned on [RVL-CDIP](https://adamharley.com/rvl-cdip/), a subset of the former\n",
    "consisting of 400000 grayscale document images split evenly across 16 classes.\n",
    "\n",
    "The model achieves an accuracy of roughly 93% of the test set.\n",
    "\n",
    "Since the model's accuracy is pretty high it is, as expected, well calibrated\n",
    "(pre-calibration ECE â‰ˆ 0.069, post-calibration ECE <= 0.03).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from kyle.evaluation import EvalStats\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoFeatureExtractor, AutoModelForImageClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is needed for notebooks in case jupyter is started directly in the notebooks directory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_working_directory = Path(\".\").resolve()\n",
    "if current_working_directory.name == \"notebooks\":\n",
    "    sys.path.insert(0, os.fspath(current_working_directory.parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.constants import DATA_DIR, OUTPUT_DIR, RANDOM_SEED\n",
    "from src.data_and_models.rvl_cdip import download_rvl_cdip\n",
    "from src.utils import (\n",
    "    RVLCDIPDataset,\n",
    "    configure_plots,\n",
    "    open_image,\n",
    "    perform_default_evaluation,\n",
    "    plot_evaluation_results_from_dataframe,\n",
    "    set_random_seed,\n",
    ")\n",
    "from src.utils.evaluation import combined_results_into_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = OUTPUT_DIR / \"deit_rvl_cdip\"\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "output_file = output_dir / \"results.csv\"\n",
    "\n",
    "rvl_cdip_dir = DATA_DIR / \"deit_rvl_cdip\"\n",
    "images_dir = rvl_cdip_dir / \"dataset\" / \"images\"\n",
    "labels_dir = rvl_cdip_dir / \"dataset\" / \"labels\"\n",
    "features_array_file = rvl_cdip_dir / \"dataset\" / \"features.np\"\n",
    "test_labels_file = labels_dir / \"test.txt\"\n",
    "validation_labels_file = labels_dir / \"val.txt\"\n",
    "training_labels_file = labels_dir / \"train.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"microsoft/dit-base-finetuned-rvlcdip\"\n",
    "batch_size = 64\n",
    "label2idx = {\n",
    "    \"letter\": 0,\n",
    "    \"form\": 1,\n",
    "    \"email\": 2,\n",
    "    \"handwritten\": 3,\n",
    "    \"advertisement\": 4,\n",
    "    \"scientific_report\": 5,\n",
    "    \"scientific_publication\": 6,\n",
    "    \"specification\": 7,\n",
    "    \"file_folder\": 8,\n",
    "    \"news_article\": 9,\n",
    "    \"budget\": 10,\n",
    "    \"invoice\": 11,\n",
    "    \"presentation\": 12,\n",
    "    \"questionnaire\": 13,\n",
    "    \"resume\": 14,\n",
    "    \"memo\": 15,\n",
    "}\n",
    "idx2label = {v: k for k, v in label2idx.items()}\n",
    "n_classes = len(label2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seed(RANDOM_SEED)\n",
    "configure_plots()\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(message)s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_rvl_cdip(rvl_cdip_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "\n",
    "for label_file in [test_labels_file, validation_labels_file]:\n",
    "    with label_file.open(\"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        for line in tqdm(lines):\n",
    "            relative_image_path, label = line.strip().split()\n",
    "            image_path = images_dir / relative_image_path\n",
    "            assert image_path.is_file()\n",
    "            if open_image(image_path) is None:\n",
    "                continue\n",
    "            images.append(os.fspath(image_path))\n",
    "            labels.append(int(label))\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(model_name)\n",
    "\n",
    "image = open_image(images[0])\n",
    "x = feature_extractor(images=image, return_tensors=\"np\")[\"pixel_values\"][0]\n",
    "\n",
    "features_array = np.memmap(\n",
    "    filename=os.fspath(features_array_file),\n",
    "    shape=(len(labels), *x.shape),\n",
    "    dtype=float,\n",
    "    mode=\"w+\",\n",
    ")\n",
    "\n",
    "for i, image_file in tqdm(enumerate(images), total=len(images)):\n",
    "    image = open_image(image_file)\n",
    "    x = feature_extractor(images=image, return_tensors=\"np\")[\"pixel_values\"][0]\n",
    "    features_array[i] = x\n",
    "\n",
    "dataset = RVLCDIPDataset(\n",
    "    features=features_array,\n",
    "    labels=labels,\n",
    ")\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForImageClassification.from_pretrained(model_name)\n",
    "model = model.float()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Calibration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Generating model predictions on test set\")\n",
    "\n",
    "uncalibrated_confidences = []\n",
    "y_true = []\n",
    "\n",
    "for batch in tqdm(dataloader, total=len(dataloader)):\n",
    "    features = batch[\"features\"].float()\n",
    "    labels = batch[\"label\"]\n",
    "    with torch.no_grad():\n",
    "        predictions = model(pixel_values=features)\n",
    "    logits = predictions.logits\n",
    "    y_true.append(labels.detach().numpy())\n",
    "    confidences = torch.nn.functional.softmax(logits, dim=1)\n",
    "    uncalibrated_confidences.append(confidences.detach().numpy())\n",
    "\n",
    "y_true = np.concatenate(y_true, axis=0)[:, 0]\n",
    "uncalibrated_confidences = np.concatenate(uncalibrated_confidences, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(uncalibrated_confidences, axis=1)\n",
    "model_accuracy = accuracy_score(y_true, y_pred)\n",
    "logger.info(f\"Model accuracy: {model_accuracy*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_stats = EvalStats(y_true, uncalibrated_confidences, bins=25)\n",
    "logger.info(f\"ECE before calibration: {eval_stats.expected_calibration_error()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recalibration\n",
    "We evaluate reduction wrappers on multiple metrics with different calibration algorithms\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanced\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Performing evaluation\")\n",
    "\n",
    "eval_results = perform_default_evaluation(\n",
    "    confidences=uncalibrated_confidences,\n",
    "    gt_labels=y_true,\n",
    ")\n",
    "\n",
    "results_df = combined_results_into_dataframe(\n",
    "    eval_results,\n",
    "    model_name=\"DeiT\",\n",
    "    dataset_name=\"RVL-CDIP\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction_methods_order: List[str] = results_df[\"Reduction Method\"].unique().tolist()\n",
    "reduction_methods_order = [reduction_methods_order[0]] + sorted(\n",
    "    reduction_methods_order[1:], key=len\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Saving results\")\n",
    "results_df.to_csv(output_file, sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Plotting results\")\n",
    "\n",
    "results_df = results_df.query(\"(Metric != 'condition') & (Metric != 'weak_condition')\")\n",
    "\n",
    "plot_evaluation_results_from_dataframe(\n",
    "    results_df,\n",
    "    hue_order=reduction_methods_order,\n",
    "    output_file=(output_dir / \"evaluation_ECE_deit_rvl_cdip.eps\"),\n",
    "    show=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
